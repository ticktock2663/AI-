{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XD4mMMvTClu7","executionInfo":{"status":"error","timestamp":1668511665126,"user_tz":-540,"elapsed":280,"user":{"displayName":"남재각","userId":"07979346138965257816"}},"outputId":"89d3abe6-81bf-4533-c791-9b07938aa428"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ee6461cac727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:\\\\Users\\competition_data/water_data/*.csv\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\competition_data/water_data/*.csv\")'"]}],"source":["import os\n","os.chdir('C:\\\\Users\\competition_data/water_data/*.csv\")')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"14EeVSn5Clu-","executionInfo":{"status":"error","timestamp":1668511622792,"user_tz":-540,"elapsed":4540,"user":{"displayName":"남재각","userId":"07979346138965257816"}},"outputId":"1b346f18-798c-4586-b5ce-526ee2dee4b0"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-112c9cf9e57e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import pandas as pd\n","import numpy as np\n","\n","from glob import glob\n","from tqdm import tqdm\n","from scipy import interpolate\n","\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, GRU, AveragePooling1D, GlobalAveragePooling1D\n","\n","#GPU 자원이 부족한 경우 아래 코드를 이용하세요\n","from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","\n","import tensorflow_addons as tfa\n","from keras import backend as K\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWwVIQfyClvA","executionInfo":{"status":"aborted","timestamp":1668511603803,"user_tz":-540,"elapsed":11,"user":{"displayName":"남재각","userId":"07979346138965257816"}}},"outputs":[],"source":["rf_list = sorted(glob(\"rf_data/*.csv\"))\n","rf_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrVbBic9ClvB","executionInfo":{"status":"aborted","timestamp":1668511603804,"user_tz":-540,"elapsed":12,"user":{"displayName":"남재각","userId":"07979346138965257816"}}},"outputs":[],"source":["w_list = sorted(glob(\"water_data/*.csv\"))\n","w_list"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Yvrkx3lQClvC"},"outputs":[],"source":["#전체 데이터 병합후 저장\n","\n","for i in range(len(rf_list)):\n","    pd.concat([pd.read_csv(rf_list[i], index_col = 0),pd.read_csv(w_list[i], index_col = 0)], axis=1).to_csv('full_data/f_list_'+str(i).zfill(2)+'.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CPwfa2vVClvC","outputId":"36e1a876-1369-4900-c525-b31b6ea8a24c"},"outputs":[{"data":{"text/plain":["['full_data\\\\f_list_00.csv',\n"," 'full_data\\\\f_list_01.csv',\n"," 'full_data\\\\f_list_02.csv',\n"," 'full_data\\\\f_list_03.csv',\n"," 'full_data\\\\f_list_04.csv',\n"," 'full_data\\\\f_list_05.csv',\n"," 'full_data\\\\f_list_06.csv',\n"," 'full_data\\\\f_list_07.csv',\n"," 'full_data\\\\f_list_08.csv',\n"," 'full_data\\\\f_list_09.csv',\n"," 'full_data\\\\f_list_10.csv']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# 병합데이터 불러오기\n","\n","f_list = sorted(glob(\"full_data/*.csv\")) #\n","f_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qeMZvOgyClvD","outputId":"805f866f-fa0f-4e49-d5dd-22a3a6f02c90"},"outputs":[{"data":{"text/plain":["(26496, 18)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv(f_list[0]).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFVae5EzClvE","outputId":"a6c9b809-d151-497b-9f57-082ef9d1b0b1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ymdhm</th>\n","      <th>rf_10184100</th>\n","      <th>rf_10184110</th>\n","      <th>rf_10184140</th>\n","      <th>swl</th>\n","      <th>inf</th>\n","      <th>sfw</th>\n","      <th>ecpc</th>\n","      <th>tototf</th>\n","      <th>tide_level</th>\n","      <th>wl_1018662</th>\n","      <th>fw_1018662</th>\n","      <th>wl_1018680</th>\n","      <th>fw_1018680</th>\n","      <th>wl_1018683</th>\n","      <th>fw_1018683</th>\n","      <th>wl_1019630</th>\n","      <th>fw_1019630</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2012-05-01 00:00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24.800</td>\n","      <td>555.0</td>\n","      <td>219.07</td>\n","      <td>24.93</td>\n","      <td>555.0</td>\n","      <td>445.0</td>\n","      <td>310.7</td>\n","      <td>469.05</td>\n","      <td>300.2</td>\n","      <td>0.0</td>\n","      <td>290.0</td>\n","      <td>729.80</td>\n","      <td>275.3</td>\n","      <td>540.18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2012-05-01 00:10</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24.794</td>\n","      <td>464.6</td>\n","      <td>218.86</td>\n","      <td>25.15</td>\n","      <td>562.9</td>\n","      <td>449.0</td>\n","      <td>314.7</td>\n","      <td>498.00</td>\n","      <td>300.2</td>\n","      <td>0.0</td>\n","      <td>290.0</td>\n","      <td>731.48</td>\n","      <td>275.3</td>\n","      <td>540.18</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2012-05-01 00:20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24.789</td>\n","      <td>478.1</td>\n","      <td>218.69</td>\n","      <td>25.31</td>\n","      <td>576.4</td>\n","      <td>451.0</td>\n","      <td>313.7</td>\n","      <td>490.68</td>\n","      <td>301.2</td>\n","      <td>0.0</td>\n","      <td>290.0</td>\n","      <td>726.42</td>\n","      <td>275.3</td>\n","      <td>540.18</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2012-05-01 00:30</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>24.789</td>\n","      <td>464.8</td>\n","      <td>218.69</td>\n","      <td>25.31</td>\n","      <td>563.1</td>\n","      <td>452.0</td>\n","      <td>311.7</td>\n","      <td>476.21</td>\n","      <td>301.2</td>\n","      <td>0.0</td>\n","      <td>290.0</td>\n","      <td>726.42</td>\n","      <td>276.3</td>\n","      <td>552.17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              ymdhm  rf_10184100  rf_10184110  rf_10184140     swl    inf  \\\n","0  2012-05-01 00:00          0.0          0.0          0.0  24.800  555.0   \n","1  2012-05-01 00:10          0.0          0.0          0.0  24.794  464.6   \n","2  2012-05-01 00:20          0.0          0.0          0.0  24.789  478.1   \n","3  2012-05-01 00:30          0.0          0.0          0.0  24.789  464.8   \n","\n","      sfw   ecpc  tototf  tide_level  wl_1018662  fw_1018662  wl_1018680  \\\n","0  219.07  24.93   555.0       445.0       310.7      469.05       300.2   \n","1  218.86  25.15   562.9       449.0       314.7      498.00       300.2   \n","2  218.69  25.31   576.4       451.0       313.7      490.68       301.2   \n","3  218.69  25.31   563.1       452.0       311.7      476.21       301.2   \n","\n","   fw_1018680  wl_1018683  fw_1018683  wl_1019630  fw_1019630  \n","0         0.0       290.0      729.80       275.3      540.18  \n","1         0.0       290.0      731.48       275.3      540.18  \n","2         0.0       290.0      726.42       275.3      540.18  \n","3         0.0       290.0      726.42       276.3      552.17  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv(f_list[0]).head(4)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"tit-34ScClvE","outputId":"4bc41692-c951-4840-8dde-f7005014ff62"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 26466/26466 [00:19<00:00, 1358.00it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1361.56it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1354.18it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1332.36it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1368.18it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1370.59it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1355.98it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1373.57it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1361.14it/s]\n","100%|██████████| 26466/26466 [00:19<00:00, 1373.29it/s]\n"]}],"source":["#window_size 200으로 묶어 train dataset 만들기\n","\n","train_data = []\n","train_label = []\n","num = 0\n","\n","window = 30\n","\n","for i in f_list[:-1]:\n","    \n","    tmp = pd.read_csv(i)\n","    \n","    # 10분전, 20분전 데이터와의 차이값을 추가 변수로 활용\n","    \n","    tmp[[\"wl_1018662_1\", \"wl_1018680_1\", \"wl_1018683_1\", \"wl_1019630_1\"]] = tmp[[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]].reset_index(drop=True) - pd.concat([tmp[:1][[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]],\n","                                                                                                             tmp[:-1][[\"wl_1018662\", \"wl_1018680\",\"wl_1018683\",\"wl_1019630\"]]], axis = 0).reset_index(drop=True)\n","    tmp[[\"wl_1018662_2\", \"wl_1018680_2\", \"wl_1018683_2\", \"wl_1019630_2\"]] = tmp[[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]].reset_index(drop=True) - pd.concat([tmp[:2][[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]],\n","                                                                                                             tmp[:-2][[\"wl_1018662\", \"wl_1018680\",\"wl_1018683\",\"wl_1019630\"]]], axis = 0).reset_index(drop=True)\n","\n","    tmp = tmp.replace(\" \", np.nan)\n","    tmp = tmp.interpolate(method = 'values')\n","    tmp = tmp.fillna(0)\n","\n","    for j in tqdm(range(len(tmp)-window)):\n","        train_data.append(np.array(tmp.loc[j:j + window-1,\n","                                           ['rf_10184100','rf_10184110','rf_10184140',\"swl\", \"inf\", \"sfw\", \"ecpc\",\n","                                            \"tototf\", \"tide_level\",\"fw_1018662\", \"fw_1018680\",\"fw_1018683\", \"fw_1019630\",\n","                                            \"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\",\n","                                            \"wl_1018662_1\", \"wl_1018680_1\", \"wl_1018683_1\", \"wl_1019630_1\",\n","                                           \"wl_1018662_2\", \"wl_1018680_2\", \"wl_1018683_2\", \"wl_1019630_2\"]]).astype(float))\n","        \n","        train_label.append(np.array(tmp.loc[j + window, [\"wl_1018662\", \"wl_1018680\",\n","                                                      \"wl_1018683\", \"wl_1019630\"]]).astype(float))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUiAyWBMClvG","outputId":"baa9f176-cd6f-4702-ffc7-18dcab194059"},"outputs":[{"name":"stdout","output_type":"stream","text":["(264660, 30, 25)\n","(264660, 4)\n"]}],"source":["# Train dataset을 계속 사용할 수 있도록 저장\n","\n","train_data = np.array(train_data)\n","train_label = np.array(train_label)\n","\n","print(train_data.shape)\n","print(train_label.shape)\n","\n","np.save(\"train_data2.npy\",train_data)\n","np.save(\"train_label2.npy\",train_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVHK0mD0ClvG"},"outputs":[],"source":["# Train dataset 불러오기\n","\n","train_data = np.load(\"train_data2.npy\")\n","train_label = np.load(\"train_label2.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CamMQ7PWClvH"},"outputs":[],"source":["#metric 및 loss함수로 사용할 함수 지정\n","\n","def r2(y_true, y_pred):\n","    SS_res =  K.sum(K.square( y_true-y_pred ))\n","    SS_tot = K.sum(K.square( y_true - K.mean(y_true)))\n","    return (1 - SS_res/(SS_tot + K.epsilon()))\n","\n","def rmse(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n","\n","def score(y_test, y_pred):\n","    return rmse(y_test, y_pred) / r2(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irOq-w4iClvI","outputId":"2a6fcdca-a312-4c51-edb2-25163c853eb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d (Conv1D)              (None, 28, 256)           19456     \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 14, 256)           0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 12, 512)           393728    \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 6, 512)            0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 4, 64)             98368     \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 2, 64)             0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 128)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 4)                 516       \n","=================================================================\n","Total params: 512,068\n","Trainable params: 512,068\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["input_shape = (train_data[0].shape[0], train_data[0].shape[1])\n","\n","model = Sequential()\n","#model.add(GRU(256, input_shape=input_shape))\n","#model.add(GRU(32, return_sequences=False))\n","#model.add(Dense(4, activation = 'relu'))\n","\n","model.add(layers.Conv1D(256, (3), activation='relu', input_shape=input_shape))\n","model.add(layers.MaxPooling1D((2)))\n","model.add(layers.Conv1D(512, (3), activation='relu', input_shape=input_shape))\n","model.add(layers.MaxPooling1D((2)))\n","model.add(layers.Conv1D(64, (3), activation='relu', input_shape=input_shape))\n","model.add(layers.MaxPooling1D((2)))\n","model.add(layers.Flatten())\n","model.add(Dense(4, activation = 'relu'))\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,\n","                                     beta_1=0.9,\n","                                     beta_2=0.999,\n","                                     epsilon=1e-07)\n","\n","# loss 함수에 score함수를 지정하였으나 학습속도가 너무 느려 rmse를 활용\n","model.compile(optimizer=optimizer,loss = rmse, metrics=[score,'mae'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CrVpuG6ClvI","outputId":"fe07a192-2311-4943-8794-6fcdff13b835"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","259/259 [==============================] - 9s 21ms/step - loss: 38.4507 - score: 24.9487 - mae: 34.5693\n","Epoch 2/100\n","259/259 [==============================] - 6s 21ms/step - loss: 6.7865 - score: 6.9654 - mae: 6.0678\n","Epoch 3/100\n","259/259 [==============================] - 5s 21ms/step - loss: 9.4956 - score: 9.8246 - mae: 8.8527\n","Epoch 4/100\n","259/259 [==============================] - 5s 21ms/step - loss: 7.4748 - score: 7.6204 - mae: 6.8499\n","Epoch 5/100\n","259/259 [==============================] - 5s 21ms/step - loss: 6.7634 - score: 6.8718 - mae: 6.1516\n","Epoch 6/100\n","259/259 [==============================] - 5s 21ms/step - loss: 6.0235 - score: 6.1061 - mae: 5.4148\n","Epoch 7/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.7668 - score: 3.7858 - mae: 3.2095\n","Epoch 8/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.8690 - score: 3.8906 - mae: 3.3494\n","Epoch 9/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.7403 - score: 3.7594 - mae: 3.2522\n","Epoch 10/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.7609 - score: 3.7827 - mae: 3.2951\n","Epoch 11/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.6924 - score: 3.7113 - mae: 3.2318\n","Epoch 12/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.5295 - score: 3.5461 - mae: 3.0833\n","Epoch 13/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.6722 - score: 3.6904 - mae: 3.2080\n","Epoch 14/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.2557 - score: 3.2692 - mae: 2.8440\n","Epoch 15/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.3162 - score: 3.3298 - mae: 2.9309\n","Epoch 16/100\n","259/259 [==============================] - 5s 21ms/step - loss: 4.0871 - score: 4.1229 - mae: 3.6785\n","Epoch 17/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.2019 - score: 3.2158 - mae: 2.8140\n","Epoch 18/100\n","259/259 [==============================] - 5s 21ms/step - loss: 4.1681 - score: 4.2041 - mae: 3.7870\n","Epoch 19/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.4509 - score: 3.4698 - mae: 3.0676\n","Epoch 20/100\n","259/259 [==============================] - 5s 21ms/step - loss: 2.8845 - score: 2.8933 - mae: 2.5165\n","Epoch 21/100\n","259/259 [==============================] - 5s 21ms/step - loss: 2.8537 - score: 2.8623 - mae: 2.4962\n","Epoch 22/100\n","259/259 [==============================] - 5s 21ms/step - loss: 2.8071 - score: 2.8151 - mae: 2.4422\n","Epoch 23/100\n","259/259 [==============================] - 5s 21ms/step - loss: 3.0035 - score: 3.0147 - mae: 2.6412\n","Epoch 24/100\n","259/259 [==============================] - 6s 21ms/step - loss: 2.8023 - score: 2.8102 - mae: 2.4630\n","Epoch 25/100\n","259/259 [==============================] - 5s 21ms/step - loss: 2.7957 - score: 2.8040 - mae: 2.4522\n","Epoch 26/100\n","259/259 [==============================] - 5s 21ms/step - loss: 2.7266 - score: 2.7340 - mae: 2.3772\n","Epoch 27/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.6980 - score: 2.7051 - mae: 2.3644\n","Epoch 28/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.8237 - score: 2.8329 - mae: 2.4949\n","Epoch 29/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.8385 - score: 2.8486 - mae: 2.5015\n","Epoch 30/100\n","259/259 [==============================] - 5s 20ms/step - loss: 4.7940 - score: 4.8308 - mae: 4.4875\n","Epoch 31/100\n","259/259 [==============================] - 5s 20ms/step - loss: 4.2365 - score: 4.2622 - mae: 3.8675\n","Epoch 32/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.3958 - score: 2.4008 - mae: 2.0564\n","Epoch 33/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.3679 - score: 2.3728 - mae: 2.0518\n","Epoch 34/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.4674 - score: 2.4731 - mae: 2.1420\n","Epoch 35/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.4544 - score: 2.4598 - mae: 2.1447\n","Epoch 36/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.4236 - score: 2.4289 - mae: 2.1049\n","Epoch 37/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.5610 - score: 2.5678 - mae: 2.2517\n","Epoch 38/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.4046 - score: 2.4095 - mae: 2.1029\n","Epoch 39/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.4092 - score: 2.4142 - mae: 2.1017\n","Epoch 40/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.3737 - score: 2.3783 - mae: 2.0575\n","Epoch 41/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.3402 - score: 2.3449 - mae: 2.0307\n","Epoch 42/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.4160 - score: 2.4214 - mae: 2.1127\n","Epoch 43/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.2548 - score: 2.2593 - mae: 1.9585\n","Epoch 44/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.3030 - score: 2.3074 - mae: 2.0163\n","Epoch 45/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.2930 - score: 2.2973 - mae: 2.0024\n","Epoch 46/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.2274 - score: 2.2313 - mae: 1.9270\n","Epoch 47/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.2812 - score: 2.2856 - mae: 1.9804\n","Epoch 48/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.3681 - score: 2.3733 - mae: 2.0631\n","Epoch 49/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.3408 - score: 2.3461 - mae: 2.0533\n","Epoch 50/100\n","259/259 [==============================] - 5s 21ms/step - loss: 2.1621 - score: 2.1658 - mae: 1.8858\n","Epoch 51/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.2176 - score: 2.2215 - mae: 1.9314\n","Epoch 52/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.2453 - score: 2.2494 - mae: 1.9369\n","Epoch 53/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.1514 - score: 2.1551 - mae: 1.8746\n","Epoch 54/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.1587 - score: 2.1624 - mae: 1.8818\n","Epoch 55/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.2073 - score: 2.2114 - mae: 1.9291\n","Epoch 56/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0844 - score: 2.0876 - mae: 1.8231\n","Epoch 57/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0872 - score: 2.0905 - mae: 1.8087\n","Epoch 58/100\n","259/259 [==============================] - 5s 21ms/step - loss: 2.0846 - score: 2.0878 - mae: 1.8083\n","Epoch 59/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.1141 - score: 2.1177 - mae: 1.8439\n","Epoch 60/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0559 - score: 2.0590 - mae: 1.7921\n","Epoch 61/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0360 - score: 2.0391 - mae: 1.7608\n","Epoch 62/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0528 - score: 2.0559 - mae: 1.7801\n","Epoch 63/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0208 - score: 2.0238 - mae: 1.7456\n","Epoch 64/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0370 - score: 2.0400 - mae: 1.7770\n","Epoch 65/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.0062 - score: 2.0090 - mae: 1.7453\n","Epoch 66/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.1089 - score: 2.1124 - mae: 1.8283\n","Epoch 67/100\n","259/259 [==============================] - 5s 20ms/step - loss: 2.9517 - score: 2.9639 - mae: 2.6721\n","Epoch 68/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8751 - score: 1.8776 - mae: 1.6211\n","Epoch 69/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9518 - score: 1.9544 - mae: 1.7039\n","Epoch 70/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9553 - score: 1.9578 - mae: 1.6967\n","Epoch 71/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9196 - score: 1.9220 - mae: 1.6594\n","Epoch 72/100\n"]},{"name":"stdout","output_type":"stream","text":["259/259 [==============================] - 5s 20ms/step - loss: 1.9265 - score: 1.9290 - mae: 1.6757\n","Epoch 73/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9485 - score: 1.9511 - mae: 1.6970\n","Epoch 74/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9370 - score: 1.9396 - mae: 1.6778\n","Epoch 75/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9203 - score: 1.9229 - mae: 1.6681\n","Epoch 76/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9274 - score: 1.9300 - mae: 1.6753\n","Epoch 77/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9189 - score: 1.9214 - mae: 1.6803\n","Epoch 78/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9070 - score: 1.9096 - mae: 1.6537\n","Epoch 79/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9341 - score: 1.9367 - mae: 1.6772\n","Epoch 80/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8588 - score: 1.8611 - mae: 1.6105\n","Epoch 81/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9120 - score: 1.9146 - mae: 1.6663\n","Epoch 82/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9210 - score: 1.9236 - mae: 1.6691\n","Epoch 83/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9137 - score: 1.9163 - mae: 1.6721\n","Epoch 84/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8535 - score: 1.8558 - mae: 1.6093\n","Epoch 85/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8872 - score: 1.8896 - mae: 1.6517\n","Epoch 86/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8843 - score: 1.8868 - mae: 1.6368\n","Epoch 87/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8778 - score: 1.8803 - mae: 1.6336\n","Epoch 88/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.9721 - score: 1.9750 - mae: 1.7264\n","Epoch 89/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8713 - score: 1.8737 - mae: 1.6291\n","Epoch 90/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8682 - score: 1.8704 - mae: 1.6242\n","Epoch 91/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8429 - score: 1.8451 - mae: 1.6044\n","Epoch 92/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8642 - score: 1.8665 - mae: 1.6228\n","Epoch 93/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8023 - score: 1.8044 - mae: 1.5596\n","Epoch 94/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8822 - score: 1.8847 - mae: 1.6368\n","Epoch 95/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8134 - score: 1.8155 - mae: 1.5620\n","Epoch 96/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.7980 - score: 1.8002 - mae: 1.5588\n","Epoch 97/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8456 - score: 1.8479 - mae: 1.6078\n","Epoch 98/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.8036 - score: 1.8056 - mae: 1.5719\n","Epoch 99/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.7830 - score: 1.7850 - mae: 1.5509\n","Epoch 100/100\n","259/259 [==============================] - 5s 20ms/step - loss: 1.7849 - score: 1.7869 - mae: 1.5507\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x1761239a610>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(train_data, train_label, epochs=100, batch_size=1024) \n","# batch_size는 512를 사용하여도 생각외로 높은 성능을 보임\n","# 시간이 많다면 epoch를 크게 높이는 것도 방법..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uUO4eQRClvJ","outputId":"74697d49-640d-470f-898c-f7eae397b59e"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-17-cc1cb63b7a94>:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  tmp['wl_1018662'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1018662']\n","<ipython-input-17-cc1cb63b7a94>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  tmp['wl_1018680'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1018680']\n","<ipython-input-17-cc1cb63b7a94>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  tmp['wl_1018683'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1018683']\n","<ipython-input-17-cc1cb63b7a94>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  tmp['wl_1019630'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1019630']\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ymdhm</th>\n","      <th>rf_10184100</th>\n","      <th>rf_10184110</th>\n","      <th>rf_10184140</th>\n","      <th>swl</th>\n","      <th>inf</th>\n","      <th>sfw</th>\n","      <th>ecpc</th>\n","      <th>tototf</th>\n","      <th>tide_level</th>\n","      <th>...</th>\n","      <th>wl_1019630</th>\n","      <th>fw_1019630</th>\n","      <th>wl_1018662_1</th>\n","      <th>wl_1018680_1</th>\n","      <th>wl_1018683_1</th>\n","      <th>wl_1019630_1</th>\n","      <th>wl_1018662_2</th>\n","      <th>wl_1018680_2</th>\n","      <th>wl_1018683_2</th>\n","      <th>wl_1019630_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-05-01 00:00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.20</td>\n","      <td>739.36</td>\n","      <td>218.73</td>\n","      <td>25.27</td>\n","      <td>124.36</td>\n","      <td>81.0</td>\n","      <td>...</td>\n","      <td>269.3</td>\n","      <td>471.08</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-05-01 00:10</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.20</td>\n","      <td>124.48</td>\n","      <td>218.73</td>\n","      <td>25.27</td>\n","      <td>124.48</td>\n","      <td>72.0</td>\n","      <td>...</td>\n","      <td>266.3</td>\n","      <td>438.33</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-05-01 00:20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.20</td>\n","      <td>124.20</td>\n","      <td>218.73</td>\n","      <td>25.27</td>\n","      <td>124.20</td>\n","      <td>64.0</td>\n","      <td>...</td>\n","      <td>264.3</td>\n","      <td>417.17</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-5.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-05-01 00:30</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.20</td>\n","      <td>124.35</td>\n","      <td>218.73</td>\n","      <td>25.27</td>\n","      <td>124.35</td>\n","      <td>58.0</td>\n","      <td>...</td>\n","      <td>263.3</td>\n","      <td>406.79</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1.0</td>\n","      <td>-2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-05-01 00:40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.19</td>\n","      <td>0.00</td>\n","      <td>218.36</td>\n","      <td>25.64</td>\n","      <td>124.42</td>\n","      <td>58.0</td>\n","      <td>...</td>\n","      <td>264.3</td>\n","      <td>417.17</td>\n","      <td>-2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>-3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11371</th>\n","      <td>2022-07-18 23:10</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.04</td>\n","      <td>259.23</td>\n","      <td>212.86</td>\n","      <td>31.14</td>\n","      <td>259.23</td>\n","      <td>510.0</td>\n","      <td>...</td>\n","      <td>306.3</td>\n","      <td>974.40</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>3.0</td>\n","      <td>-1.0</td>\n","      <td>9.0</td>\n","      <td>17.0</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>11372</th>\n","      <td>2022-07-18 23:20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.04</td>\n","      <td>260.46</td>\n","      <td>212.86</td>\n","      <td>31.14</td>\n","      <td>260.46</td>\n","      <td>492.0</td>\n","      <td>...</td>\n","      <td>308.3</td>\n","      <td>1006.88</td>\n","      <td>-1.0</td>\n","      <td>8.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>-1.0</td>\n","      <td>17.0</td>\n","      <td>14.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>11373</th>\n","      <td>2022-07-18 23:30</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.04</td>\n","      <td>259.37</td>\n","      <td>212.86</td>\n","      <td>31.14</td>\n","      <td>259.37</td>\n","      <td>475.0</td>\n","      <td>...</td>\n","      <td>310.3</td>\n","      <td>1039.90</td>\n","      <td>12.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>11.0</td>\n","      <td>12.0</td>\n","      <td>10.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>11374</th>\n","      <td>2022-07-18 23:40</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.04</td>\n","      <td>259.13</td>\n","      <td>212.86</td>\n","      <td>31.14</td>\n","      <td>259.13</td>\n","      <td>458.0</td>\n","      <td>...</td>\n","      <td>312.3</td>\n","      <td>1073.46</td>\n","      <td>10.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>22.0</td>\n","      <td>8.0</td>\n","      <td>10.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>11375</th>\n","      <td>2022-07-18 23:50</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>25.04</td>\n","      <td>258.16</td>\n","      <td>212.86</td>\n","      <td>31.14</td>\n","      <td>258.16</td>\n","      <td>442.0</td>\n","      <td>...</td>\n","      <td>313.3</td>\n","      <td>1090.45</td>\n","      <td>17.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>27.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11376 rows × 26 columns</p>\n","</div>"],"text/plain":["                  ymdhm  rf_10184100  rf_10184110  rf_10184140    swl     inf  \\\n","0      2022-05-01 00:00          0.0          0.0          0.0  25.20  739.36   \n","1      2022-05-01 00:10          0.0          0.0          0.0  25.20  124.48   \n","2      2022-05-01 00:20          0.0          0.0          0.0  25.20  124.20   \n","3      2022-05-01 00:30          0.0          0.0          0.0  25.20  124.35   \n","4      2022-05-01 00:40          0.0          0.0          0.0  25.19    0.00   \n","...                 ...          ...          ...          ...    ...     ...   \n","11371  2022-07-18 23:10          0.0          0.0          0.0  25.04  259.23   \n","11372  2022-07-18 23:20          0.0          0.0          0.0  25.04  260.46   \n","11373  2022-07-18 23:30          0.0          0.0          0.0  25.04  259.37   \n","11374  2022-07-18 23:40          0.0          0.0          0.0  25.04  259.13   \n","11375  2022-07-18 23:50          0.0          0.0          0.0  25.04  258.16   \n","\n","          sfw   ecpc  tototf  tide_level  ...  wl_1019630  fw_1019630  \\\n","0      218.73  25.27  124.36        81.0  ...       269.3      471.08   \n","1      218.73  25.27  124.48        72.0  ...       266.3      438.33   \n","2      218.73  25.27  124.20        64.0  ...       264.3      417.17   \n","3      218.73  25.27  124.35        58.0  ...       263.3      406.79   \n","4      218.36  25.64  124.42        58.0  ...       264.3      417.17   \n","...       ...    ...     ...         ...  ...         ...         ...   \n","11371  212.86  31.14  259.23       510.0  ...       306.3      974.40   \n","11372  212.86  31.14  260.46       492.0  ...       308.3     1006.88   \n","11373  212.86  31.14  259.37       475.0  ...       310.3     1039.90   \n","11374  212.86  31.14  259.13       458.0  ...       312.3     1073.46   \n","11375  212.86  31.14  258.16       442.0  ...       313.3     1090.45   \n","\n","       wl_1018662_1  wl_1018680_1  wl_1018683_1  wl_1019630_1  wl_1018662_2  \\\n","0               0.0           0.0           0.0           0.0           0.0   \n","1               1.0           0.0           0.0          -3.0           0.0   \n","2              -1.0           0.0           0.0          -2.0           0.0   \n","3              -1.0           0.0           0.0          -1.0          -2.0   \n","4              -2.0           0.0           0.0           1.0          -3.0   \n","...             ...           ...           ...           ...           ...   \n","11371           0.0           9.0           9.0           3.0          -1.0   \n","11372          -1.0           8.0           5.0           2.0          -1.0   \n","11373          12.0           4.0           5.0           2.0          11.0   \n","11374          10.0           4.0           5.0           2.0          22.0   \n","11375          17.0           3.0           3.0           1.0          27.0   \n","\n","       wl_1018680_2  wl_1018683_2  wl_1019630_2  \n","0               0.0           0.0           0.0  \n","1               0.0           0.0           0.0  \n","2               0.0           0.0          -5.0  \n","3               0.0           0.0          -3.0  \n","4               0.0           0.0           0.0  \n","...             ...           ...           ...  \n","11371           9.0          17.0           7.0  \n","11372          17.0          14.0           5.0  \n","11373          12.0          10.0           4.0  \n","11374           8.0          10.0           4.0  \n","11375           7.0           8.0           3.0  \n","\n","[11376 rows x 26 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# 검증용 데이터 만들기\n","test_data = []\n","\n","tmp = pd.read_csv(f_list[-1])\n","tmp = tmp.replace(\" \", np.nan)\n","tmp = tmp.fillna(method = 'pad')\n","tmp = tmp.fillna(0)\n","tmp.index = tmp.ymdhm\n","\n","tmp['wl_1018662'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1018662']\n","tmp['wl_1018680'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1018680']\n","tmp['wl_1018683'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1018683']\n","tmp['wl_1019630'].iloc[-6912:] = pd.read_csv(\"정답_submission.csv\", index_col = 'ymdhm')['wl_1019630']\n","\n","tmp = tmp.reset_index(drop=True)\n","\n","tmp[[\"wl_1018662_1\", \"wl_1018680_1\", \"wl_1018683_1\", \"wl_1019630_1\"]] = tmp[[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]] - pd.concat([tmp[:1][[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]], tmp[:-1][[\"wl_1018662\", \"wl_1018680\",\"wl_1018683\",\"wl_1019630\"]]], axis = 0).reset_index(drop=True)  \n","tmp[[\"wl_1018662_2\", \"wl_1018680_2\", \"wl_1018683_2\", \"wl_1019630_2\"]] = tmp[[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]] - pd.concat([tmp[:2][[\"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\"]], tmp[:-2][[\"wl_1018662\", \"wl_1018680\",\"wl_1018683\",\"wl_1019630\"]]], axis = 0).reset_index(drop=True)\n","\n","tmp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18TMPlOSClvK","outputId":"410d879a-0c78-4ab8-e209-47b15d4daf2c"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 11346/11346 [00:04<00:00, 2364.58it/s]\n"]}],"source":["for j in tqdm(range(len(tmp)-window)): \n","    test_data.append(np.array(tmp.loc[j:j + window-1,\n","                                      ['rf_10184100','rf_10184110','rf_10184140',\"swl\", \"inf\", \"sfw\", \"ecpc\",\n","                                       \"tototf\", \"tide_level\",\"fw_1018662\", \"fw_1018680\",\"fw_1018683\", \"fw_1019630\",\n","                                       \"wl_1018662\", \"wl_1018680\", \"wl_1018683\",\"wl_1019630\",\n","                                       \"wl_1018662_1\", \"wl_1018680_1\", \"wl_1018683_1\", \"wl_1019630_1\",\n","                                       \"wl_1018662_2\", \"wl_1018680_2\", \"wl_1018683_2\", \"wl_1019630_2\"]]).astype(float))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LqwDO8mClvL","outputId":"c3efcf34-aaec-489d-acc2-f98afa3e8e5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(11346, 30, 25)\n","(30, 25)\n"]}],"source":["test_data = np.array(test_data)\n","\n","print(test_data.shape)\n","print(test_data[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJniKJZOClvM"},"outputs":[],"source":["#제출 파일 만들기\n","\n","pred = model.predict(test_data[-6912:])\n","pred = pd.DataFrame(pred)\n","\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\n","\n","sample_submission[\"wl_1018662\"] = pred[0]\n","sample_submission[\"wl_1018680\"] = pred[1]\n","sample_submission[\"wl_1018683\"] = pred[2]\n","sample_submission[\"wl_1019630\"] = pred[3]\n","\n","sample_submission.to_csv(\"baseline.csv\", index = False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}